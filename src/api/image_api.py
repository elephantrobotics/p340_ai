"""
qwen_api.py

OpenCVè°ƒç”¨æ¨¡å—, ä¸»è¦è´Ÿè´£è¿›è¡Œå›¾åƒå¤„ç†

Author: Zhu Jiahao
Date: 2025-07-17
"""

import cv2
import numpy as np
from typing import List, Tuple, Optional
from PIL import Image, ImageDraw, ImageFont
import base64
import os
import json
from src.utils.config import __config__
from src.utils.logger import __logger__

__all__ = ['OpenCVImageClient']

cv_logger = __logger__.get_module_logger("OpenCV")

class OpenCVImageClient:
    """ OpenCVå›¾åƒå¤„ç†ç±»
    """
    def __init__(self,
                camera_id: int):
        """
        åˆå§‹åŒ–

        Args:
            camera_id (int): æ‘„åƒå¤´ç´¢å¼•
        """
        self.camera_id = camera_id
        self.image_num = 0
        self.cap: Optional[cv2.VideoCapture] = None

    def capture_single_image(self, capture_path: str) -> None:
        """ æ‰“å¼€æ‘„åƒå¤´å¹¶æ•è·ä¸€å¼ å›¾åƒ

        Args:
            capture_path (str): å›¾åƒå­˜å‚¨è·¯å¾„
        """
        cv_logger.info("æ­£åœ¨å¼€å¯æ‘„åƒå¤´...")

        self.cap = cv2.VideoCapture(self.camera_id)
        if not self.cap.isOpened():
            cv_logger.error("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
        
        # è®¾ç½®åˆ†è¾¨ç‡
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3840)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2160)

        cv_logger.info("æ‘„åƒå¤´å·²å¯åŠ¨, æŒ‰ç©ºæ ¼æ‹ç…§...")

        while True:
            ret, frame = self.cap.read()
            if not ret:
                cv_logger.error("æ‘„åƒå¤´è·å–å¤±è´¥")
                break

            preview = cv2.resize(frame, (0, 0), fx=0.33, fy=0.33)
            cv2.imshow("image capture", preview)
            key = cv2.waitKey(1)

            if key == 32:     # SPACE
                rotated = self.__rotate_image(frame, 90, True)
                enhanced = self.__enhance_image(rotated)
                final = self.__process_for_a4(enhanced)

                cv2.imwrite(capture_path, final)
                cv_logger.info(f"å›¾ç‰‡å·²ä¿å­˜: {capture_path}")
                break
        
        self.cap.release()
        cv2.destroyAllWindows()

    def capture_multi_images(self, capture_path: str) -> List:
        """ æ‰“å¼€æ‘„åƒå¤´å¹¶æ•è·å¤šå¼ å›¾åƒ
        
        Args:
            capture_path (str): å›¾åƒå­˜å‚¨è·¯å¾„

        Return:
            æ–‡ä»¶åˆ—è¡¨
        """
        cv_logger.info("æ­£åœ¨å¼€å¯æ‘„åƒå¤´...")

        self.cap = cv2.VideoCapture(self.camera_id)
        if not self.cap.isOpened():
            cv_logger.error("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        
        # è®¾ç½®åˆ†è¾¨ç‡
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 3840)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 2160)

        file_list = []
        cv_logger.info("æ‘„åƒå¤´å·²å¯åŠ¨, æŒ‰ç©ºæ ¼æ‹ç…§, ESCç»“æŸã€‚")

        while True:
            ret, frame = self.cap.read()
            if not ret:
                cv_logger.error("æ‘„åƒå¤´è·å–å¤±è´¥")
                break

            preview = cv2.resize(frame, (0, 0), fx=0.33, fy=0.33)
            cv2.imshow("image capture", preview)
            key = cv2.waitKey(1)

            if key == 27:       # ESC
                cv_logger.info("ç”¨æˆ·é€€å‡ºå›¾åƒæ•è·æ¨¡å¼")
                break
            elif key == 32:     # SPACE
                self.image_num += 1
                cv_logger.info(f"æ‹æ‘„äº†ç¬¬{self.image_num}é¡µ")

                rotated = self.__rotate_image(frame, 90, True)
                enhanced = self.__enhance_image(rotated)
                final = self.__process_for_a4(enhanced)

                filename = os.path.join(capture_path, f"{self.image_num}.jpg")
                cv2.imwrite(filename, final)
                cv_logger.info(f"å›¾ç‰‡å·²ä¿å­˜: {filename}")
                file_list.append(filename)

        self.cap.release()
        cv2.destroyAllWindows()
        return file_list

    def load_image_and_get_scale(self, image_path: str) -> Tuple:
        """ åŠ è½½å›¾åƒå¹¶è®¡ç®—æ¯«ç±³å’Œåƒç´ é—´çš„è½¬æ¢æ¯”ä¾‹

        Args:
            image_path (str): å›¾ç‰‡è·¯å¾„

        Return:
            tuple: åŒ…å«ä»¥ä¸‹å…ƒç´ çš„å…ƒç»„
                - img (numpy.ndarray): åŠ è½½çš„å›¾åƒæ•°ç»„
                - img_w (int): å›¾åƒå®½åº¦(åƒç´ )
                - img_h (int): å›¾åƒé«˜åº¦(åƒç´ )
                - mm_per_pixel_x (float): æ°´å¹³æ–¹å‘æ¯åƒç´ å¯¹åº”çš„æ¯«ç±³æ•°
                - mm_per_pixel_y (float): å‚ç›´æ–¹å‘æ¯åƒç´ å¯¹åº”çš„æ¯«ç±³æ•°
                - px_per_mm_y (float): å‚ç›´æ–¹å‘æ¯æ¯«ç±³å¯¹åº”çš„åƒç´ æ•°
        """
        # å®šä¹‰A4çº¸çš„æ ‡å‡†å°ºå¯¸(æ¯«ç±³)
        A4_WIDTH_MM = 210
        A4_HEIGHT_MM = 297

        # åŠ è½½å›¾åƒ
        img = cv2.imread(image_path)
        if img is None:
            cv_logger.error("æœªèƒ½æ‰“å¼€å›¾åƒ...")
            return 
        
        # è·å–å›¾åƒå°ºå¯¸
        img_h, img_w = img.shape[:2]
        
        mm_per_pixel_x = A4_WIDTH_MM / img_w        
        mm_per_pixel_y = A4_HEIGHT_MM / img_h       
        px_per_mm_y = img_h / A4_HEIGHT_MM          

        return img, img_w, img_h, mm_per_pixel_x, mm_per_pixel_y, px_per_mm_y

    def detect_single_black_box(self, img: np.ndarray, log_path: str, min_area: int=500) -> Tuple:
        """
        æ£€æµ‹å›¾åƒä¸­å”¯ä¸€çš„é»‘è‰²é—­åˆçŸ©å½¢æ¡†ï¼Œå¹¶å°†å…¶ç»˜åˆ¶åˆ°æœ¬åœ°å›¾ç‰‡ã€‚
        è¦æ±‚å›¾åƒåªå­˜åœ¨ä¸€ä¸ªé»‘æ¡†ï¼Œè‡ªåŠ¨æ’é™¤å°è½®å»“æˆ–å™ªå£°ã€‚

        Args:
            img (np.ndarray): BGRå›¾åƒ
            log_path (str): æ—¥å¿—å­˜å‚¨è·¯å¾„
            min_area (int): æœ€å°æœ‰æ•ˆåŒºåŸŸï¼ˆå•ä½ï¼šåƒç´ å¹³æ–¹ï¼‰ï¼Œç”¨äºæ’é™¤å™ªå£°å°æ¡†

        Return:
            Tuple(x, y, w, h, area)
        """        
        bin_mask = self.__get_black_mask(img)
        contours = self.__find_external_contours(bin_mask)

        # è¿‡æ»¤æ‰é¢ç§¯å¤ªå°çš„å™ªå£°
        boxes = []
        for cnt in contours:
            area = cv2.contourArea(cnt)
            if area < min_area:
                continue
            x, y, w, h = cv2.boundingRect(cnt)
            boxes.append((x, y, w, h, area))

        # åº”ç”¨éæå¤§å€¼æŠ‘åˆ¶åˆå¹¶é‡å æ¡†
        boxes = self.__non_max_suppression(boxes, iou_threshold=0.6)

        if len(boxes) == 0:
            raise ValueError("æœªæ£€æµ‹åˆ°é»‘æ¡†ï¼Œè¯·æ£€æŸ¥å›¾åƒè´¨é‡æˆ–é˜ˆå€¼è®¾ç½®")
        elif len(boxes) == 1:
            box = boxes[0][:4]
        else:
            # è¿”å›é¢ç§¯æœ€å¤§çš„ä¸€ä¸ªæ¡†ï¼Œå‡è®¾å®ƒæ˜¯é»‘æ¡†
            boxes.sort(key=lambda b: b[4], reverse=True)
            box = boxes[0][:4]

        self.__save_boxes_visualization(img, box, log_path)

        return box

    def generate_writing_task(self,
                            img: np.ndarray,
                            box: Tuple,
                            answer: str, 
                            mm_per_pixel_x: float, 
                            mm_per_pixel_y: float,
                            px_per_mm_y: float,
                            preview_path: str,
                            task_path: str) -> None:
        """ è§„åˆ’ä¹¦å†™ä»»åŠ¡, å¹¶ç”Ÿæˆé¢„è§ˆå›¾

        Args:
            img (np.ndarray): BGRå›¾åƒ
            box (Tuple[int, int, int, int]): é»‘æ¡†çš„(x, y, w, h)çŸ©å½¢æ¡†åæ ‡
            answer (str): ç­”æ¡ˆ
            log_path (str): æ—¥å¿—ä¿å­˜è·¯å¾„
            mm_per_pixel_x (float): æ°´å¹³æ–¹å‘æ¯åƒç´ å¯¹åº”çš„æ¯«ç±³æ•°
            mm_per_pixel_y (float): å‚ç›´æ–¹å‘æ¯åƒç´ å¯¹åº”çš„æ¯«ç±³æ•°
            px_per_mm_y (float): å‚ç›´æ–¹å‘æ¯æ¯«ç±³å¯¹åº”çš„åƒç´ æ•°
            preview_path (str): é¢„è§ˆå›¾ç”Ÿæˆè·¯å¾„
            task_path (str): ä»»åŠ¡æ–‡ä»¶ç”Ÿæˆè·¯å¾„
        """
        pil_img = Image.fromarray(cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)
        font_path = r"C:\Windows\Fonts\simfang.ttf"
        if not os.path.exists(font_path):
            cv_logger.error(f"ä»¿å®‹å­—ä½“æ–‡ä»¶ä¸å­˜åœ¨: {font_path}")
            return
        
        writing_tasks = []
        cv_logger.info("")

        x, y, w, h = box
        # å°†åƒç´ æ¢ç®—æˆæ¯«ç±³
        box_w_mm = w * mm_per_pixel_x
        box_h_mm = h * mm_per_pixel_y
        # å­—å·æ§åˆ¶
        max_font_mm = min(10.0, box_h_mm, box_w_mm / len(answer) * 1.5 if answer else 10.0)
        min_font_mm = 8.0
        if box_h_mm < min_font_mm: min_font_mm = box_h_mm
        # æ¢ç®—å›åƒç´ 
        max_font_px = max(int(max_font_mm * px_per_mm_y), 1)    
        min_font_px = max(int(min_font_mm * px_per_mm_y), 1)
        # å°è¯•åˆé€‚çš„å­—å·å¹¶è‡ªåŠ¨æ¢è¡Œ
        text_box_w = int(w * 0.8)
        text_box_h = int(h * 0.95)

        # final_lines, final_font, line_height = [], None, 0
        # for font_px in range(max_font_px, min_font_px - 1, -1):
        #     font = ImageFont.truetype(font_path, font_px)
        #     lines = self.__wrap_text(answer, font, text_box_w, draw)
        #     lh = font.getbbox("æ±‰")[3] - font.getbbox("æ±‰")[1]
        #     if lh * len(lines) <= text_box_h:
        #         final_lines, final_font, line_height = lines, font, lh
        #         break

        # print(max_font_px, max_font_mm, line_height)

        # # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚å­—å·ï¼Œå¼ºè¡Œç”¨æœ€å°å­—å·
        # if not final_font:
        # ä½¿ç”¨å›ºå®šå­—å· (ä¸å†è‡ªé€‚åº”)
        final_font = ImageFont.truetype(font_path, min_font_px)
        final_lines = self.__wrap_text(answer, final_font, text_box_w, draw)
        line_height = final_font.getbbox("æ±‰")[3] - final_font.getbbox("æ±‰")[1]

        # è®¡ç®—æ–‡å­—èµ·å§‹ä½ç½®, å®ç°å±…ä¸­æ’ç‰ˆ
        # max_line_width = max(draw.textlength(line, font=final_font) for line in final_lines)
        # x_start = x + (w - max_line_width) / 2
        # y_start = y + (h - line_height * len(final_lines)) / 2
        max_line_w_px = max(draw.textbbox((0,0), line, font=final_font)[2] for line in final_lines) if final_lines else 0
        total_text_h_px = line_height * len(final_lines)
        x_start = x + (w - max_line_w_px) / 2
        y_start = y + (h - total_text_h_px) / 3

        # ç»˜åˆ¶æ–‡å­—, ä¿å­˜ä¹¦å†™ä»»åŠ¡
        char_height_mm = (final_font.size / px_per_mm_y) * 0.8  # ä¼°ç®—å­—ç¬¦é«˜åº¦
        for i, line in enumerate(final_lines):
            y_line = y_start + i * line_height
            draw.text((x_start, y_line), line, font=final_font, fill=(0, 0, 0))
            writing_tasks.append({
                "text": line,
                "a4_x_mm": x_start * mm_per_pixel_x,
                "a4_y_mm": y_line * mm_per_pixel_y,
                "char_height_mm": char_height_mm,
                "char_spacing_ratio": 1.2
            })

        # ä¿å­˜é¢„è§ˆå›¾
        annotated_bgr = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        cv2.imwrite(preview_path, annotated_bgr)
        cv_logger.info(f"é¢„è§ˆå›¾å·²ä¿å­˜è‡³: {preview_path}")
        
        with open(task_path, "w", encoding="utf-8") as f:
            json.dump(writing_tasks, f, ensure_ascii=False, indent=2)
        print(f"âœ… å†™å­—ä»»åŠ¡å·²ä¿å­˜è‡³: {task_path}")




    """
    =================================================================================
                                    ä»¥ä¸‹æ˜¯ç§æœ‰å‡½æ•°
    =================================================================================
    """
     
    def __enhance_image(self, image: np.ndarray) -> np.ndarray:
        """ å›¾åƒå¢å¼º: å¢åŠ å¯¹æ¯”åº¦, çªå‡ºçº¢è‰²

        Args:
            image (np.ndarray): è¾“å…¥å›¾åƒ

        Returns:
            np.ndarray: æ—‹è½¬åçš„å›¾åƒ
        """
        enhanced_image = cv2.convertScaleAbs(image, alpha=1.3, beta=0)
        hsv = cv2.cvtColor(enhanced_image, cv2.COLOR_BGR2HSV)
        h, s, v = cv2.split(hsv)

        red_mask = cv2.inRange(h, 0, 10) + cv2.inRange(h, 170, 180)
        s_red = np.where(red_mask > 0, np.clip(s * 2.0, 0, 255).astype(np.uint8), s)
        non_red_mask = cv2.bitwise_not(red_mask)
        s_combined = np.where(non_red_mask > 0, np.clip(s * 0.6, 0, 255).astype(np.uint8), s_red)

        final_hsv = cv2.merge([h, s_combined, v])
        return cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
    
    def __rotate_image(self, image: np.ndarray, angle: int = 90, clockwise: bool = False) -> np.ndarray:
        """
        æ—‹è½¬å›¾åƒ

        Args:
            image (np.ndarray): è¾“å…¥å›¾åƒ
            angle (int): æ—‹è½¬è§’åº¦ï¼Œå¯é€‰å€¼ä¸º 90, 180, 270
            clockwise (bool): æ˜¯å¦é¡ºæ—¶é’ˆæ—‹è½¬ï¼Œé»˜è®¤ False è¡¨ç¤ºé€†æ—¶é’ˆ

        Returns:
            np.ndarray: æ—‹è½¬åçš„å›¾åƒ

        Raises:
            ValueError: å¦‚æœè§’åº¦æ— æ•ˆ
        """
        angle = angle % 360
        if angle not in (90, 180, 270):
            raise ValueError("ä»…æ”¯æŒæ—‹è½¬è§’åº¦ä¸º 90, 180, 270")

        # OpenCV çš„æ—‹è½¬æ ‡å¿—æ˜ å°„
        rotate_map = {
            (90, False): cv2.ROTATE_90_COUNTERCLOCKWISE,
            (90, True): cv2.ROTATE_90_CLOCKWISE,
            (180, False): cv2.ROTATE_180,
            (180, True): cv2.ROTATE_180,
            (270, False): cv2.ROTATE_90_CLOCKWISE,
            (270, True): cv2.ROTATE_90_COUNTERCLOCKWISE,
        }

        rotate_code = rotate_map.get((angle, clockwise))
        return cv2.rotate(image, rotate_code)
    
    def __process_for_a4(self, image: np.ndarray) -> np.ndarray:
        """ å°†å›¾åƒè£å‰ªæˆA4æ¯”ä¾‹

        Args:
            image (np.ndarray): è¾“å…¥å›¾åƒ

        Returns:
            np.ndarray: æ—‹è½¬åçš„å›¾åƒ
        """
        TARGET_WIDTH = 2100
        TOP_CROP_MM = 62
        BOTTOM_CROP_MM = 10

        h, w, _ = image.shape
        ratio = TARGET_WIDTH / w
        new_height = int(h * ratio)
        resized = cv2.resize(image, (TARGET_WIDTH, new_height), interpolation=cv2.INTER_AREA)

        px_per_mm = TARGET_WIDTH / 210
        top = int(TOP_CROP_MM * px_per_mm)
        bottom = int(BOTTOM_CROP_MM * px_per_mm)

        if top >= new_height - bottom:
            cv_logger.info(f"è­¦å‘Šï¼šå›¾åƒå¤ªå°æ— æ³•è£å‰ªï¼Œè¿”å›åŸå›¾ã€‚")
            return resized
        
        cropped = resized[top:new_height - bottom, :]
        cv_logger.info(f"å›¾ç‰‡å·²å¤„ç†ï¼šç¼©æ”¾({TARGET_WIDTH}x{new_height})ï¼Œè£å‰ªä¸Šä¸‹({top}px, {bottom}px)")
        return cropped

    def __get_black_mask(self, image: np.ndarray) -> np.ndarray:
        """ è·å–å›¾åƒä¸­çš„é»‘è‰²åŒºåŸŸæ©ç 

        Args: 
            image (np.ndarray): BGRå›¾åƒ

        Return:
            æ©ç 
        """    
        # hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        # lower_red1, upper_red1 = np.array([0, 43, 46]), np.array([10, 255, 255])
        # lower_red2, upper_red2 = np.array([156, 43, 46]), np.array([180, 255, 255])
        # mask_red = cv2.bitwise_or(cv2.inRange(hsv, lower_red1, upper_red1), cv2.inRange(hsv, lower_red2, upper_red2))
        # kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        # mask_clean = cv2.morphologyEx(mask_red, cv2.MORPH_CLOSE, kernel, iterations=2)
        # mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel, iterations=1)

        # è½¬æ¢ä¸ºHSVé¢œè‰²ç©ºé—´
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        # å®šä¹‰é»‘è‰²çš„HSVèŒƒå›´
        lower_black = np.array([0, 0, 0])     
        upper_black = np.array([180, 255, 100]) 

        # ç”Ÿæˆé»‘è‰²åŒºåŸŸçš„æ©è†œ
        mask_black = cv2.inRange(hsv, lower_black, upper_black)

        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        mask_clean = cv2.morphologyEx(mask_black, cv2.MORPH_CLOSE, kernel, iterations=2)
        mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel, iterations=1)

        return mask_clean
    
    def __find_external_contours(self, mask: np.ndarray) -> list:
        """ ä»æ©ç ä¸­æå–å¤–éƒ¨è½®å»“

        Args:
            mask: æ©ç 

        Return:
            å¤–éƒ¨è½®å»“
        """
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        return contours
    
    def __save_boxes_visualization(self, img: np.ndarray, box: Tuple, log_path: str) -> None:
        """
        ä¿å­˜ç”»å‡ºé»‘æ¡†å’Œè§’ç‚¹åæ ‡çš„ä¸­é—´å›¾åƒï¼Œä¾¿äºè°ƒè¯•å’Œ UI æ˜¾ç¤ºã€‚
        
        å‚æ•°:
            img (np.ndarray): åŸå§‹å›¾åƒï¼ˆBGRæ ¼å¼ï¼‰
            box (Tuple[int, int, int, int]): é»‘æ¡†çš„(x, y, w, h)çŸ©å½¢æ¡†åæ ‡
            log_path (str): ä¿å­˜ç»˜å›¾å›¾åƒçš„ç›®æ ‡ç›®å½•
        """
        img_vis = img.copy()
        font = cv2.FONT_HERSHEY_SIMPLEX

        x, y, w, h = box  # è§£åŒ…å•ä¸ªçŸ©å½¢æ¡†
        cv2.rectangle(img_vis, (x, y), (x + w, y + h), (0, 255, 0), 2)

        coords = [(x, y), (x + w, y), (x, y + h), (x + w, y + h)]
        for cx, cy in coords:
            text = f"({cx},{cy})"
            cv2.putText(img_vis, text, (cx, cy - 5), font, 0.4, (255, 0, 0), 1)

        cv2.imwrite(log_path, img_vis)
        cv_logger.info(f"åæ ‡å›¾ä¿å­˜è‡³: {log_path}")

    def __non_max_suppression(self, boxes, iou_threshold=0.6):
        """
        å¯¹è¾“å…¥çš„è¾¹ç•Œæ¡†åˆ—è¡¨æ‰§è¡Œéæå¤§å€¼æŠ‘åˆ¶ï¼Œåˆå¹¶é«˜åº¦é‡å çš„æ¡†ã€‚
        ä¸ä¼ ç»Ÿçš„NMSä¸åŒï¼Œè¿™é‡Œæˆ‘ä»¬åˆå¹¶æ¡†è€Œä¸æ˜¯ç®€å•åˆ é™¤ï¼Œä»¥åº”å¯¹åŒä¸€ä¸ªæ¡†è¢«åˆ†å‰²æ£€æµ‹çš„æƒ…å†µã€‚
        
        Args:
            boxes (list): æ ¼å¼ä¸º [(x, y, w, h), ...] çš„æ¡†åˆ—è¡¨ã€‚
            iou_threshold (float): IoUé˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼çš„æ¡†å°†è¢«åˆå¹¶ã€‚

        Returns:
            list: åˆå¹¶åçš„æ¡†åˆ—è¡¨ã€‚
        """
        if not boxes:
            return []

        # å°† (x, y, w, h) è½¬æ¢ä¸º (x1, y1, x2, y2)
        rects = np.array([[b[0], b[1], b[0] + b[2], b[1] + b[3]] for b in boxes])
        
        # è®¡ç®—é¢ç§¯
        areas = (rects[:, 2] - rects[:, 0]) * (rects[:, 3] - rects[:, 1])
        # æŒ‰y1åæ ‡æ’åº
        indices = np.argsort(rects[:, 1])

        merged_boxes = []
        while len(indices) > 0:
            last = len(indices) - 1
            i = indices[last]
            
            # å°†å½“å‰æ¡†åŠ å…¥åˆ°åˆå¹¶åˆ—è¡¨ä¸­
            current_rect = rects[i]
            current_area = areas[i]  # ä¿ç•™å½“å‰é¢ç§¯
            indices = np.delete(indices, last)

            # å¯»æ‰¾ä¸å½“å‰æ¡†é«˜åº¦é‡å çš„å…¶ä»–æ¡†
            suppress = [last]
            for pos in range(len(indices)):
                j = indices[pos]
                
                # è®¡ç®— IoU
                xx1 = np.maximum(current_rect[0], rects[j][0])
                yy1 = np.maximum(current_rect[1], rects[j][1])
                xx2 = np.minimum(current_rect[2], rects[j][2])
                yy2 = np.minimum(current_rect[3], rects[j][3])

                w = np.maximum(0, xx2 - xx1)
                h = np.maximum(0, yy2 - yy1)
                
                intersection = w * h
                union = areas[i] + areas[j] - intersection
                iou = intersection / union if union > 0 else 0
                
                # å¦‚æœ IoU è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™åˆå¹¶è¿™ä¸¤ä¸ªæ¡†
                if iou > iou_threshold:
                    # åˆå¹¶æ¡†ï¼šå–ä¸¤ä¸ªæ¡†çš„æœ€å¤§å¤–æ¥çŸ©å½¢
                    current_rect[0] = min(current_rect[0], rects[j][0])
                    current_rect[1] = min(current_rect[1], rects[j][1])
                    current_rect[2] = max(current_rect[2], rects[j][2])
                    current_rect[3] = max(current_rect[3], rects[j][3])
                    current_area += areas[j]  # ç´¯åŠ åˆå¹¶çš„é¢ç§¯
                    
                    # æ ‡è®°æ­¤æ¡†ï¼Œä»¥ä¾¿åç»­åˆ é™¤
                    suppress.append(pos)
            
            # ä»ç´¢å¼•ä¸­åˆ é™¤å·²è¢«åˆå¹¶çš„æ¡†
            indices = np.delete(indices, [s for s in suppress if s != last])
            
            # å°†åˆå¹¶åçš„å¤§æ¡† (x1, y1, x2, y2) è½¬æ¢å› (x, y, w, h)
            merged_w = current_rect[2] - current_rect[0]
            merged_h = current_rect[3] - current_rect[1]
            merged_boxes.append((int(current_rect[0]), int(current_rect[1]), int(merged_w), int(merged_h), int(current_area)))
            
        cv_logger.info(f"ğŸ“¦ éæå¤§å€¼æŠ‘åˆ¶ï¼šåŸå§‹æ£€æµ‹åˆ° {len(boxes)} ä¸ªæ¡†ï¼Œåˆå¹¶åå‰©ä½™ {len(merged_boxes)} ä¸ªæ¡†ã€‚")
        return merged_boxes

    def __wrap_text(self, text: str, font: str, max_width: float, draw):
        """å°†æ–‡æœ¬åœ¨æŒ‡å®šå®½åº¦å†…è‡ªåŠ¨æ¢è¡Œ
        
        Args:
            text (str): è¦ä¹¦å†™çš„æ–‡æœ¬
            font (ImageFont): 
        """
        lines, current = [], ""
        for ch in text:
            # ä½¿ç”¨ getbbox è®¡ç®—å½“å‰æ–‡æœ¬å®½åº¦
            bbox = draw.textbbox((0, 0), current + ch, font=font)
            text_width = bbox[2] - bbox[0]  # x_max - x_min
            
            if text_width > max_width:
                lines.append(current)
                current = ch
            else:
                current += ch
        
        if current:
            lines.append(current)
        
        return lines

